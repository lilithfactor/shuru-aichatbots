{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing libraries\n!pip install --upgrade openai\nimport numpy as np\nimport pandas as pd\nimport os\nimport openai\nimport time\nfrom kaggle_secrets import UserSecretsClient","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# api key\napikey = \"enter_api_key\"\nmid = \"enter_model_id\" # enter model id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up Openai\n# OPENAI_API_KEY = UserSecretsClient().get_secret(secret_label)\n# openai.api_key = OPENAI_API_KEY\nopenai.api_key = apikey\nOPENAI_API_KEY = apikey","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean completions\ndef cleanCompletions(txt):\n    gp = \"\\n\".join(txt.split(\"\\n\\n\"))\n    \n    #removing incomplete responses\n    #stp = sp.rfind(\".\")\n    return gp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# completion\n#run model using modelid and return response\ndef model(mid, apikey):\n    #5.run model\n    #read parameters\n    print(\"\\nPlease Enter the following parameters.\\n\")\n    prefix = \"Enter_a_suitable_prefix\"\n    prompt = input('Prompt: ')\n    t = float(input(\"Temperature (0-1): \"))\n    fp = float(input(\"Frequency Penalty (0-2): \"))\n    pp = float(input(\"Presence Penalty (0-2): \"))\n    try:\n        response = openai.Completion.create(\n            model= mid, #model id\n            prompt=prefix+prompt+\" ->\", #prompt\n            max_tokens=100, #max tokens\n            temperature=t, #increase for random responses\n            # top_p=1, #top probability\n            frequency_penalty=fp, #increase for non unique responses\n            presence_penalty=pp, #increase for new topics\n            stop=[\"###\"]\n        )\n    except Exception as err:\n        print(f\"Unable to Create Completion :( .\\nUnexpected {err}, {type(err)}\")\n        raise\n    else:\n        print(\"\\n||| Models Response. |||\\n\\n\")\n        return cleanCompletions(response['choices'][0]['text'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get completion to get response\nresponse = model(\n    mid=mid,\n    apikey=OPENAI_API_KEY\n)\nprint(response)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}